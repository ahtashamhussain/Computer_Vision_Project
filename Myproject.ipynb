{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DBBCmzM3RLB",
        "outputId": "53455693-30d9-4bd4-ba4b-c251e2f124e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfLo2Hs4ZD84",
        "outputId": "66c799dc-d9ed-4439-ff2b-ea379603c74e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/CV project/data/image': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#!ls /content/drive/MyDrive/CV\\ project/data/image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Outc_YHGZiM0",
        "is_executing": true
      },
      "outputs": [],
      "source": [
        " #!7za -y x \"/content/drive/MyDrive/CV project/data/image/origin.7z.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpfkLdh92AGe"
      },
      "outputs": [],
      "source": [
        " #!cp -r ./origin \"/content/drive/MyDrive/CV project\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "CKdTRQ-b2yBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbEInQG02441"
      },
      "outputs": [],
      "source": [
        "images_folder_path=r\"/content/drive/MyDrive/Colab Notebooks/processed_data/origin\"\n",
        "label_file_path=r\"/content/drive/MyDrive/data/label/label.lst\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "eeJ2rV-qGLtH",
        "outputId": "8318d00c-82d3-4257-f984-4f630744ed9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            image_name  face_id_in_image  face_box_top  face_box_left  \\\n",
              "0  angry_actor_104.jpg                 0            28            113   \n",
              "1  angry_actor_109.jpg                 0            31            157   \n",
              "2  angry_actor_120.jpg                 1            53             53   \n",
              "3   angry_actor_13.jpg                 0            77             51   \n",
              "4  angry_actor_132.jpg                 0            95             31   \n",
              "\n",
              "   face_box_right  face_box_bottom  face_box_cofidence  expression_label  \n",
              "0             226              141             22.9362                 0  \n",
              "1             345              219             50.3056                 0  \n",
              "2             372              372             13.9434                 2  \n",
              "3             362              388             85.8104                 3  \n",
              "4             412              476             82.3948                 0  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-690599a6-377f-42b8-9ea0-583a83c76b85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>face_id_in_image</th>\n",
              "      <th>face_box_top</th>\n",
              "      <th>face_box_left</th>\n",
              "      <th>face_box_right</th>\n",
              "      <th>face_box_bottom</th>\n",
              "      <th>face_box_cofidence</th>\n",
              "      <th>expression_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>angry_actor_104.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>113</td>\n",
              "      <td>226</td>\n",
              "      <td>141</td>\n",
              "      <td>22.9362</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>angry_actor_109.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>157</td>\n",
              "      <td>345</td>\n",
              "      <td>219</td>\n",
              "      <td>50.3056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>angry_actor_120.jpg</td>\n",
              "      <td>1</td>\n",
              "      <td>53</td>\n",
              "      <td>53</td>\n",
              "      <td>372</td>\n",
              "      <td>372</td>\n",
              "      <td>13.9434</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>angry_actor_13.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>51</td>\n",
              "      <td>362</td>\n",
              "      <td>388</td>\n",
              "      <td>85.8104</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>angry_actor_132.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>31</td>\n",
              "      <td>412</td>\n",
              "      <td>476</td>\n",
              "      <td>82.3948</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-690599a6-377f-42b8-9ea0-583a83c76b85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-09299429-ef01-454e-8860-7b22a56396c8\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09299429-ef01-454e-8860-7b22a56396c8')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-09299429-ef01-454e-8860-7b22a56396c8 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-690599a6-377f-42b8-9ea0-583a83c76b85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-690599a6-377f-42b8-9ea0-583a83c76b85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "from numpy import split\n",
        "import pandas as pd\n",
        "df_info = pd.read_csv(label_file_path,sep=\" \",header=None)\n",
        "col_names=\"image_name face_id_in_image face_box_top face_box_left face_box_right face_box_bottom face_box_cofidence expression_label\".split()\n",
        "df_info.columns = col_names\n",
        "\n",
        "df_info.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOCDsU7-GOkO"
      },
      "outputs": [],
      "source": [
        "df_sel=df_info[df_info.face_box_cofidence>30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmiHwpZqGUox",
        "outputId": "f75cada8-9318-4a96-f59d-42ef70491abb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69405, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "df_sel.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph is Optional it is just to visualize the data"
      ],
      "metadata": {
        "id": "cJfS6aS1gig8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "X8BgqMvybZ5k",
        "outputId": "cc368c93-ca4c-4019-c9ed-29e5672e3c87"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot a bar chart for expression labels\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='expression_label', data=df_info)\n",
        "plt.xlabel('Expression Label')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Distribution of Expression Labels')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MODVOKNH80eq"
      },
      "outputs": [],
      "source": [
        "from numpy.core.fromnumeric import resize\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "x = []\n",
        "y = []\n",
        "for i, row in df_sel.sample(100).iterrows():\n",
        "    img_name = row[\"image_name\"]\n",
        "    x1 = row[\"face_box_left\"]\n",
        "    x2 = row[\"face_box_right\"]\n",
        "    y1 = row[\"face_box_top\"]\n",
        "    y2 = row[\"face_box_bottom\"]\n",
        "    label = row[\"expression_label\"]\n",
        "    img_path = os.path.join(images_folder_path, img_name)\n",
        "    img = cv2.imread(img_path)\n",
        "    # Check if img is not None\n",
        "    if img is not None:\n",
        "    #     # Crop the image using the provided coordinates\n",
        "         cropped_img = img[y1:y2, x1:x2]\n",
        "    else:\n",
        "        continue\n",
        "\n",
        "    if cropped_img is not None:\n",
        "      resized_face = cv2.resize(cropped_img , ( 64,64))\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "    x.append(resized_face)\n",
        "    y.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pq6PXlvAnIK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X=np.array(x)\n",
        "Y=np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pspxmi85kOj",
        "outputId": "fbadbf3c-892a-439a-cfb4-3af82a3c4e68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[229, 250, 227],\n",
              "         [230, 250, 227],\n",
              "         [233, 253, 230],\n",
              "         ...,\n",
              "         [223, 244, 222],\n",
              "         [221, 242, 220],\n",
              "         [221, 242, 220]],\n",
              "\n",
              "        [[228, 248, 225],\n",
              "         [229, 249, 225],\n",
              "         [229, 249, 226],\n",
              "         ...,\n",
              "         [223, 244, 222],\n",
              "         [221, 242, 220],\n",
              "         [220, 242, 220]],\n",
              "\n",
              "        [[226, 248, 224],\n",
              "         [229, 251, 227],\n",
              "         [228, 250, 226],\n",
              "         ...,\n",
              "         [222, 243, 221],\n",
              "         [220, 241, 219],\n",
              "         [220, 241, 219]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[138, 170, 196],\n",
              "         [128, 166, 192],\n",
              "         [127, 168, 192],\n",
              "         ...,\n",
              "         [ 70,  66,   6],\n",
              "         [ 99,  94,  11],\n",
              "         [134, 127,  27]],\n",
              "\n",
              "        [[143, 172, 196],\n",
              "         [136, 173, 196],\n",
              "         [126, 169, 190],\n",
              "         ...,\n",
              "         [ 70,  66,  12],\n",
              "         [ 88,  84,   6],\n",
              "         [118, 113,  14]],\n",
              "\n",
              "        [[144, 173, 195],\n",
              "         [139, 174, 197],\n",
              "         [128, 169, 190],\n",
              "         ...,\n",
              "         [ 80,  71,  22],\n",
              "         [ 90,  84,   9],\n",
              "         [116, 110,  15]]],\n",
              "\n",
              "\n",
              "       [[[ 43,  45,  34],\n",
              "         [ 47,  48,  37],\n",
              "         [ 40,  42,  31],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[ 40,  43,  28],\n",
              "         [ 35,  37,  24],\n",
              "         [ 32,  34,  22],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[ 44,  47,  31],\n",
              "         [ 33,  36,  21],\n",
              "         [ 26,  29,  14],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[104, 108, 112],\n",
              "         [102, 111, 107],\n",
              "         [102, 112, 106],\n",
              "         ...,\n",
              "         [239, 254, 250],\n",
              "         [235, 250, 252],\n",
              "         [232, 247, 249]],\n",
              "\n",
              "        [[103, 109, 112],\n",
              "         [102, 112, 105],\n",
              "         [101, 112, 104],\n",
              "         ...,\n",
              "         [236, 252, 249],\n",
              "         [235, 250, 252],\n",
              "         [234, 248, 250]],\n",
              "\n",
              "        [[102, 111, 112],\n",
              "         [100, 110, 106],\n",
              "         [ 99, 109, 106],\n",
              "         ...,\n",
              "         [226, 246, 243],\n",
              "         [229, 244, 247],\n",
              "         [231, 246, 249]]],\n",
              "\n",
              "\n",
              "       [[[195, 200, 199],\n",
              "         [193, 198, 198],\n",
              "         [194, 199, 198],\n",
              "         ...,\n",
              "         [ 28,  29,  34],\n",
              "         [ 20,  22,  27],\n",
              "         [ 30,  33,  38]],\n",
              "\n",
              "        [[196, 201, 200],\n",
              "         [194, 198, 198],\n",
              "         [195, 200, 199],\n",
              "         ...,\n",
              "         [ 54,  49,  54],\n",
              "         [ 35,  33,  38],\n",
              "         [ 30,  33,  36]],\n",
              "\n",
              "        [[196, 201, 200],\n",
              "         [193, 198, 197],\n",
              "         [195, 200, 199],\n",
              "         ...,\n",
              "         [ 76,  70,  75],\n",
              "         [ 49,  46,  51],\n",
              "         [ 37,  40,  42]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[208, 203, 204],\n",
              "         [202, 197, 198],\n",
              "         [204, 198, 199],\n",
              "         ...,\n",
              "         [188, 207, 233],\n",
              "         [187, 209, 233],\n",
              "         [192, 214, 238]],\n",
              "\n",
              "        [[210, 203, 204],\n",
              "         [207, 197, 198],\n",
              "         [212, 199, 201],\n",
              "         ...,\n",
              "         [189, 210, 232],\n",
              "         [191, 211, 232],\n",
              "         [193, 214, 235]],\n",
              "\n",
              "        [[209, 204, 205],\n",
              "         [207, 200, 201],\n",
              "         [210, 201, 202],\n",
              "         ...,\n",
              "         [190, 210, 232],\n",
              "         [192, 211, 232],\n",
              "         [192, 212, 233]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 33,  40,  48],\n",
              "         [ 43,  41,  52],\n",
              "         [ 31,  32,  40],\n",
              "         ...,\n",
              "         [109, 117, 140],\n",
              "         [104, 110, 133],\n",
              "         [ 94, 109, 128]],\n",
              "\n",
              "        [[ 40,  47,  54],\n",
              "         [ 42,  39,  49],\n",
              "         [ 34,  35,  42],\n",
              "         ...,\n",
              "         [110, 118, 141],\n",
              "         [106, 113, 136],\n",
              "         [ 99, 112, 133]],\n",
              "\n",
              "        [[ 38,  44,  51],\n",
              "         [ 36,  35,  43],\n",
              "         [ 38,  40,  46],\n",
              "         ...,\n",
              "         [117, 126, 146],\n",
              "         [120, 126, 147],\n",
              "         [102, 108, 134]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 69,  74,  99],\n",
              "         [ 65,  71,  99],\n",
              "         [ 70,  77, 108],\n",
              "         ...,\n",
              "         [160, 175, 198],\n",
              "         [104, 118, 145],\n",
              "         [ 60,  65,  91]],\n",
              "\n",
              "        [[ 65,  71,  90],\n",
              "         [ 66,  72,  94],\n",
              "         [ 72,  79, 104],\n",
              "         ...,\n",
              "         [149, 172, 196],\n",
              "         [ 82, 102, 130],\n",
              "         [ 60,  67,  94]],\n",
              "\n",
              "        [[ 65,  70,  84],\n",
              "         [ 66,  73,  89],\n",
              "         [ 73,  82, 100],\n",
              "         ...,\n",
              "         [137, 163, 189],\n",
              "         [ 67,  90, 119],\n",
              "         [ 58,  68,  96]]],\n",
              "\n",
              "\n",
              "       [[[110, 190, 237],\n",
              "         [108, 189, 234],\n",
              "         [109, 190, 235],\n",
              "         ...,\n",
              "         [ 13,   0,  10],\n",
              "         [ 13,   0,  11],\n",
              "         [ 13,   0,  10]],\n",
              "\n",
              "        [[108, 188, 235],\n",
              "         [106, 187, 232],\n",
              "         [107, 188, 233],\n",
              "         ...,\n",
              "         [ 14,   1,   9],\n",
              "         [ 14,   1,  10],\n",
              "         [ 14,   1,  10]],\n",
              "\n",
              "        [[107, 187, 234],\n",
              "         [104, 185, 231],\n",
              "         [105, 186, 231],\n",
              "         ...,\n",
              "         [ 14,   2,   8],\n",
              "         [ 14,   2,   8],\n",
              "         [ 14,   2,   9]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[109, 190, 233],\n",
              "         [110, 189, 232],\n",
              "         [110, 189, 232],\n",
              "         ...,\n",
              "         [ 39,  86, 174],\n",
              "         [ 38,  84, 168],\n",
              "         [ 30,  76, 159]],\n",
              "\n",
              "        [[112, 193, 235],\n",
              "         [112, 192, 234],\n",
              "         [111, 190, 233],\n",
              "         ...,\n",
              "         [ 40,  87, 175],\n",
              "         [ 40,  86, 171],\n",
              "         [ 28,  73, 157]],\n",
              "\n",
              "        [[114, 197, 241],\n",
              "         [111, 194, 238],\n",
              "         [110, 192, 236],\n",
              "         ...,\n",
              "         [ 36,  86, 174],\n",
              "         [ 39,  86, 174],\n",
              "         [ 28,  78, 161]]],\n",
              "\n",
              "\n",
              "       [[[ 52,  67,  88],\n",
              "         [ 64,  82, 109],\n",
              "         [ 56,  75, 117],\n",
              "         ...,\n",
              "         [ 26,  20,  20],\n",
              "         [ 42,  38,  39],\n",
              "         [143, 146, 145]],\n",
              "\n",
              "        [[ 58,  74, 100],\n",
              "         [ 72,  93, 123],\n",
              "         [ 41,  62, 107],\n",
              "         ...,\n",
              "         [ 43,  34,  35],\n",
              "         [ 33,  26,  27],\n",
              "         [ 32,  30,  30]],\n",
              "\n",
              "        [[ 59,  79, 109],\n",
              "         [ 74,  95, 131],\n",
              "         [ 49,  71, 118],\n",
              "         ...,\n",
              "         [ 42,  30,  33],\n",
              "         [ 39,  28,  30],\n",
              "         [ 28,  23,  24]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 11,  15,  16],\n",
              "         [ 22,  22,  21],\n",
              "         [ 19,  17,  16],\n",
              "         ...,\n",
              "         [143, 152, 154],\n",
              "         [172, 184, 184],\n",
              "         [157, 171, 170]],\n",
              "\n",
              "        [[  9,  14,  15],\n",
              "         [ 16,  20,  21],\n",
              "         [  7,  11,  11],\n",
              "         ...,\n",
              "         [132, 150, 147],\n",
              "         [169, 185, 181],\n",
              "         [231, 239, 238]],\n",
              "\n",
              "        [[ 15,  19,  20],\n",
              "         [ 13,  17,  18],\n",
              "         [ 11,  16,  17],\n",
              "         ...,\n",
              "         [191, 209, 204],\n",
              "         [221, 236, 230],\n",
              "         [250, 253, 253]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQ7lLwnT60gi",
        "outputId": "3203498e-36ff-48d9-eaea-ea1787298b6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 3, 4, 3, 3, 3, 6, 0, 1, 6, 3, 3, 6, 6, 4, 3, 6, 3, 1, 0, 6, 3,\n",
              "       3, 4, 3, 3, 4, 6, 6, 4, 6, 3, 6, 3, 6, 6, 3, 3, 3, 5, 1, 3, 5, 3,\n",
              "       1, 3, 3, 6, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bme-DB7R63Qs",
        "outputId": "d7ef1c90-1285-4173-e398-2f74a7336c88"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "len(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-71f_rXP-r8l",
        "outputId": "a30aaf33-c3b5-4f8d-e0bc-04da966c933a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "len(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTCPXb6pC8HG",
        "outputId": "519aebac-d972-40d2-90eb-1bf80538e12b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au_DzsO3DAli",
        "outputId": "3c8596f6-b8cb-4df7-8dbe-8453aaab3bfb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49,)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6z9M1D9DECC"
      },
      "outputs": [],
      "source": [
        "normalized_X = X / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sARdCBd3DKAr",
        "outputId": "d3c3e506-4c41-42d2-ebbc-c4a587da3de8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.89803922, 0.98039216, 0.89019608],\n",
              "         [0.90196078, 0.98039216, 0.89019608],\n",
              "         [0.91372549, 0.99215686, 0.90196078],\n",
              "         ...,\n",
              "         [0.8745098 , 0.95686275, 0.87058824],\n",
              "         [0.86666667, 0.94901961, 0.8627451 ],\n",
              "         [0.86666667, 0.94901961, 0.8627451 ]],\n",
              "\n",
              "        [[0.89411765, 0.97254902, 0.88235294],\n",
              "         [0.89803922, 0.97647059, 0.88235294],\n",
              "         [0.89803922, 0.97647059, 0.88627451],\n",
              "         ...,\n",
              "         [0.8745098 , 0.95686275, 0.87058824],\n",
              "         [0.86666667, 0.94901961, 0.8627451 ],\n",
              "         [0.8627451 , 0.94901961, 0.8627451 ]],\n",
              "\n",
              "        [[0.88627451, 0.97254902, 0.87843137],\n",
              "         [0.89803922, 0.98431373, 0.89019608],\n",
              "         [0.89411765, 0.98039216, 0.88627451],\n",
              "         ...,\n",
              "         [0.87058824, 0.95294118, 0.86666667],\n",
              "         [0.8627451 , 0.94509804, 0.85882353],\n",
              "         [0.8627451 , 0.94509804, 0.85882353]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.54117647, 0.66666667, 0.76862745],\n",
              "         [0.50196078, 0.65098039, 0.75294118],\n",
              "         [0.49803922, 0.65882353, 0.75294118],\n",
              "         ...,\n",
              "         [0.2745098 , 0.25882353, 0.02352941],\n",
              "         [0.38823529, 0.36862745, 0.04313725],\n",
              "         [0.5254902 , 0.49803922, 0.10588235]],\n",
              "\n",
              "        [[0.56078431, 0.6745098 , 0.76862745],\n",
              "         [0.53333333, 0.67843137, 0.76862745],\n",
              "         [0.49411765, 0.6627451 , 0.74509804],\n",
              "         ...,\n",
              "         [0.2745098 , 0.25882353, 0.04705882],\n",
              "         [0.34509804, 0.32941176, 0.02352941],\n",
              "         [0.4627451 , 0.44313725, 0.05490196]],\n",
              "\n",
              "        [[0.56470588, 0.67843137, 0.76470588],\n",
              "         [0.54509804, 0.68235294, 0.77254902],\n",
              "         [0.50196078, 0.6627451 , 0.74509804],\n",
              "         ...,\n",
              "         [0.31372549, 0.27843137, 0.08627451],\n",
              "         [0.35294118, 0.32941176, 0.03529412],\n",
              "         [0.45490196, 0.43137255, 0.05882353]]],\n",
              "\n",
              "\n",
              "       [[[0.16862745, 0.17647059, 0.13333333],\n",
              "         [0.18431373, 0.18823529, 0.14509804],\n",
              "         [0.15686275, 0.16470588, 0.12156863],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[0.15686275, 0.16862745, 0.10980392],\n",
              "         [0.1372549 , 0.14509804, 0.09411765],\n",
              "         [0.1254902 , 0.13333333, 0.08627451],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        [[0.17254902, 0.18431373, 0.12156863],\n",
              "         [0.12941176, 0.14117647, 0.08235294],\n",
              "         [0.10196078, 0.11372549, 0.05490196],\n",
              "         ...,\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ],\n",
              "         [1.        , 1.        , 1.        ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.40784314, 0.42352941, 0.43921569],\n",
              "         [0.4       , 0.43529412, 0.41960784],\n",
              "         [0.4       , 0.43921569, 0.41568627],\n",
              "         ...,\n",
              "         [0.9372549 , 0.99607843, 0.98039216],\n",
              "         [0.92156863, 0.98039216, 0.98823529],\n",
              "         [0.90980392, 0.96862745, 0.97647059]],\n",
              "\n",
              "        [[0.40392157, 0.42745098, 0.43921569],\n",
              "         [0.4       , 0.43921569, 0.41176471],\n",
              "         [0.39607843, 0.43921569, 0.40784314],\n",
              "         ...,\n",
              "         [0.9254902 , 0.98823529, 0.97647059],\n",
              "         [0.92156863, 0.98039216, 0.98823529],\n",
              "         [0.91764706, 0.97254902, 0.98039216]],\n",
              "\n",
              "        [[0.4       , 0.43529412, 0.43921569],\n",
              "         [0.39215686, 0.43137255, 0.41568627],\n",
              "         [0.38823529, 0.42745098, 0.41568627],\n",
              "         ...,\n",
              "         [0.88627451, 0.96470588, 0.95294118],\n",
              "         [0.89803922, 0.95686275, 0.96862745],\n",
              "         [0.90588235, 0.96470588, 0.97647059]]],\n",
              "\n",
              "\n",
              "       [[[0.76470588, 0.78431373, 0.78039216],\n",
              "         [0.75686275, 0.77647059, 0.77647059],\n",
              "         [0.76078431, 0.78039216, 0.77647059],\n",
              "         ...,\n",
              "         [0.10980392, 0.11372549, 0.13333333],\n",
              "         [0.07843137, 0.08627451, 0.10588235],\n",
              "         [0.11764706, 0.12941176, 0.14901961]],\n",
              "\n",
              "        [[0.76862745, 0.78823529, 0.78431373],\n",
              "         [0.76078431, 0.77647059, 0.77647059],\n",
              "         [0.76470588, 0.78431373, 0.78039216],\n",
              "         ...,\n",
              "         [0.21176471, 0.19215686, 0.21176471],\n",
              "         [0.1372549 , 0.12941176, 0.14901961],\n",
              "         [0.11764706, 0.12941176, 0.14117647]],\n",
              "\n",
              "        [[0.76862745, 0.78823529, 0.78431373],\n",
              "         [0.75686275, 0.77647059, 0.77254902],\n",
              "         [0.76470588, 0.78431373, 0.78039216],\n",
              "         ...,\n",
              "         [0.29803922, 0.2745098 , 0.29411765],\n",
              "         [0.19215686, 0.18039216, 0.2       ],\n",
              "         [0.14509804, 0.15686275, 0.16470588]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.81568627, 0.79607843, 0.8       ],\n",
              "         [0.79215686, 0.77254902, 0.77647059],\n",
              "         [0.8       , 0.77647059, 0.78039216],\n",
              "         ...,\n",
              "         [0.7372549 , 0.81176471, 0.91372549],\n",
              "         [0.73333333, 0.81960784, 0.91372549],\n",
              "         [0.75294118, 0.83921569, 0.93333333]],\n",
              "\n",
              "        [[0.82352941, 0.79607843, 0.8       ],\n",
              "         [0.81176471, 0.77254902, 0.77647059],\n",
              "         [0.83137255, 0.78039216, 0.78823529],\n",
              "         ...,\n",
              "         [0.74117647, 0.82352941, 0.90980392],\n",
              "         [0.74901961, 0.82745098, 0.90980392],\n",
              "         [0.75686275, 0.83921569, 0.92156863]],\n",
              "\n",
              "        [[0.81960784, 0.8       , 0.80392157],\n",
              "         [0.81176471, 0.78431373, 0.78823529],\n",
              "         [0.82352941, 0.78823529, 0.79215686],\n",
              "         ...,\n",
              "         [0.74509804, 0.82352941, 0.90980392],\n",
              "         [0.75294118, 0.82745098, 0.90980392],\n",
              "         [0.75294118, 0.83137255, 0.91372549]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.12941176, 0.15686275, 0.18823529],\n",
              "         [0.16862745, 0.16078431, 0.20392157],\n",
              "         [0.12156863, 0.1254902 , 0.15686275],\n",
              "         ...,\n",
              "         [0.42745098, 0.45882353, 0.54901961],\n",
              "         [0.40784314, 0.43137255, 0.52156863],\n",
              "         [0.36862745, 0.42745098, 0.50196078]],\n",
              "\n",
              "        [[0.15686275, 0.18431373, 0.21176471],\n",
              "         [0.16470588, 0.15294118, 0.19215686],\n",
              "         [0.13333333, 0.1372549 , 0.16470588],\n",
              "         ...,\n",
              "         [0.43137255, 0.4627451 , 0.55294118],\n",
              "         [0.41568627, 0.44313725, 0.53333333],\n",
              "         [0.38823529, 0.43921569, 0.52156863]],\n",
              "\n",
              "        [[0.14901961, 0.17254902, 0.2       ],\n",
              "         [0.14117647, 0.1372549 , 0.16862745],\n",
              "         [0.14901961, 0.15686275, 0.18039216],\n",
              "         ...,\n",
              "         [0.45882353, 0.49411765, 0.57254902],\n",
              "         [0.47058824, 0.49411765, 0.57647059],\n",
              "         [0.4       , 0.42352941, 0.5254902 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.27058824, 0.29019608, 0.38823529],\n",
              "         [0.25490196, 0.27843137, 0.38823529],\n",
              "         [0.2745098 , 0.30196078, 0.42352941],\n",
              "         ...,\n",
              "         [0.62745098, 0.68627451, 0.77647059],\n",
              "         [0.40784314, 0.4627451 , 0.56862745],\n",
              "         [0.23529412, 0.25490196, 0.35686275]],\n",
              "\n",
              "        [[0.25490196, 0.27843137, 0.35294118],\n",
              "         [0.25882353, 0.28235294, 0.36862745],\n",
              "         [0.28235294, 0.30980392, 0.40784314],\n",
              "         ...,\n",
              "         [0.58431373, 0.6745098 , 0.76862745],\n",
              "         [0.32156863, 0.4       , 0.50980392],\n",
              "         [0.23529412, 0.2627451 , 0.36862745]],\n",
              "\n",
              "        [[0.25490196, 0.2745098 , 0.32941176],\n",
              "         [0.25882353, 0.28627451, 0.34901961],\n",
              "         [0.28627451, 0.32156863, 0.39215686],\n",
              "         ...,\n",
              "         [0.5372549 , 0.63921569, 0.74117647],\n",
              "         [0.2627451 , 0.35294118, 0.46666667],\n",
              "         [0.22745098, 0.26666667, 0.37647059]]],\n",
              "\n",
              "\n",
              "       [[[0.43137255, 0.74509804, 0.92941176],\n",
              "         [0.42352941, 0.74117647, 0.91764706],\n",
              "         [0.42745098, 0.74509804, 0.92156863],\n",
              "         ...,\n",
              "         [0.05098039, 0.        , 0.03921569],\n",
              "         [0.05098039, 0.        , 0.04313725],\n",
              "         [0.05098039, 0.        , 0.03921569]],\n",
              "\n",
              "        [[0.42352941, 0.7372549 , 0.92156863],\n",
              "         [0.41568627, 0.73333333, 0.90980392],\n",
              "         [0.41960784, 0.7372549 , 0.91372549],\n",
              "         ...,\n",
              "         [0.05490196, 0.00392157, 0.03529412],\n",
              "         [0.05490196, 0.00392157, 0.03921569],\n",
              "         [0.05490196, 0.00392157, 0.03921569]],\n",
              "\n",
              "        [[0.41960784, 0.73333333, 0.91764706],\n",
              "         [0.40784314, 0.7254902 , 0.90588235],\n",
              "         [0.41176471, 0.72941176, 0.90588235],\n",
              "         ...,\n",
              "         [0.05490196, 0.00784314, 0.03137255],\n",
              "         [0.05490196, 0.00784314, 0.03137255],\n",
              "         [0.05490196, 0.00784314, 0.03529412]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.42745098, 0.74509804, 0.91372549],\n",
              "         [0.43137255, 0.74117647, 0.90980392],\n",
              "         [0.43137255, 0.74117647, 0.90980392],\n",
              "         ...,\n",
              "         [0.15294118, 0.3372549 , 0.68235294],\n",
              "         [0.14901961, 0.32941176, 0.65882353],\n",
              "         [0.11764706, 0.29803922, 0.62352941]],\n",
              "\n",
              "        [[0.43921569, 0.75686275, 0.92156863],\n",
              "         [0.43921569, 0.75294118, 0.91764706],\n",
              "         [0.43529412, 0.74509804, 0.91372549],\n",
              "         ...,\n",
              "         [0.15686275, 0.34117647, 0.68627451],\n",
              "         [0.15686275, 0.3372549 , 0.67058824],\n",
              "         [0.10980392, 0.28627451, 0.61568627]],\n",
              "\n",
              "        [[0.44705882, 0.77254902, 0.94509804],\n",
              "         [0.43529412, 0.76078431, 0.93333333],\n",
              "         [0.43137255, 0.75294118, 0.9254902 ],\n",
              "         ...,\n",
              "         [0.14117647, 0.3372549 , 0.68235294],\n",
              "         [0.15294118, 0.3372549 , 0.68235294],\n",
              "         [0.10980392, 0.30588235, 0.63137255]]],\n",
              "\n",
              "\n",
              "       [[[0.20392157, 0.2627451 , 0.34509804],\n",
              "         [0.25098039, 0.32156863, 0.42745098],\n",
              "         [0.21960784, 0.29411765, 0.45882353],\n",
              "         ...,\n",
              "         [0.10196078, 0.07843137, 0.07843137],\n",
              "         [0.16470588, 0.14901961, 0.15294118],\n",
              "         [0.56078431, 0.57254902, 0.56862745]],\n",
              "\n",
              "        [[0.22745098, 0.29019608, 0.39215686],\n",
              "         [0.28235294, 0.36470588, 0.48235294],\n",
              "         [0.16078431, 0.24313725, 0.41960784],\n",
              "         ...,\n",
              "         [0.16862745, 0.13333333, 0.1372549 ],\n",
              "         [0.12941176, 0.10196078, 0.10588235],\n",
              "         [0.1254902 , 0.11764706, 0.11764706]],\n",
              "\n",
              "        [[0.23137255, 0.30980392, 0.42745098],\n",
              "         [0.29019608, 0.37254902, 0.51372549],\n",
              "         [0.19215686, 0.27843137, 0.4627451 ],\n",
              "         ...,\n",
              "         [0.16470588, 0.11764706, 0.12941176],\n",
              "         [0.15294118, 0.10980392, 0.11764706],\n",
              "         [0.10980392, 0.09019608, 0.09411765]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.04313725, 0.05882353, 0.0627451 ],\n",
              "         [0.08627451, 0.08627451, 0.08235294],\n",
              "         [0.0745098 , 0.06666667, 0.0627451 ],\n",
              "         ...,\n",
              "         [0.56078431, 0.59607843, 0.60392157],\n",
              "         [0.6745098 , 0.72156863, 0.72156863],\n",
              "         [0.61568627, 0.67058824, 0.66666667]],\n",
              "\n",
              "        [[0.03529412, 0.05490196, 0.05882353],\n",
              "         [0.0627451 , 0.07843137, 0.08235294],\n",
              "         [0.02745098, 0.04313725, 0.04313725],\n",
              "         ...,\n",
              "         [0.51764706, 0.58823529, 0.57647059],\n",
              "         [0.6627451 , 0.7254902 , 0.70980392],\n",
              "         [0.90588235, 0.9372549 , 0.93333333]],\n",
              "\n",
              "        [[0.05882353, 0.0745098 , 0.07843137],\n",
              "         [0.05098039, 0.06666667, 0.07058824],\n",
              "         [0.04313725, 0.0627451 , 0.06666667],\n",
              "         ...,\n",
              "         [0.74901961, 0.81960784, 0.8       ],\n",
              "         [0.86666667, 0.9254902 , 0.90196078],\n",
              "         [0.98039216, 0.99215686, 0.99215686]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "normalized_X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J917f0gRFytP",
        "outputId": "29bcd50c-4a23-4633-8e8e-6f4b2414fcba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 34\n",
            "Validation set size: 7\n",
            "Testing set size: 8\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'x' is your input features and 'y' is the corresponding target labels\n",
        "# Replace these with your actual data arrays\n",
        "\n",
        "# Split the data into training (70%), testing (15%), and validation (15%) sets\n",
        "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Display the sizes of each split\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Validation set size:\", len(X_val))\n",
        "print(\"Testing set size:\", len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Assuming Y_train contains integer class labels ranging from 0 to 6\n",
        "Y_train_one_hot = to_categorical(Y_train, num_classes=7)\n",
        "Y_val_one_hot = to_categorical(Y_val, num_classes=7)\n"
      ],
      "metadata": {
        "id": "M_abf7y986CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "ATBeQMP2rfre",
        "outputId": "8f4c49ef-62ff-47b1-b066-682747e456ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Assuming 'x_train' is your training data and 'y_train' are the corresponding labels\n",
        "# Replace these with your actual training data and labels\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,      # Random rotation\n",
        "    width_shift_range=0.2,  # Random horizontal shift\n",
        "    height_shift_range=0.2, # Random vertical shift\n",
        "    shear_range=0.2,        # Random shear\n",
        "    zoom_range=0.2,         # Random zoom\n",
        "    horizontal_flip=True,   # Random horizontal flip\n",
        "    fill_mode='nearest'     # Fill mode for newly created pixels\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator on the training data\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Generate augmented data batches\n",
        "augmented_data_generator = datagen.flow(X_train, Y_train, batch_size=32)"
      ],
      "metadata": {
        "id": "D5pwN0_Gm1yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9euuveYHtj0",
        "outputId": "f015c06b-7945-4132-b09e-5c0355e8f5fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 12, 12, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              4719616   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 7175      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,967,623\n",
            "Trainable params: 4,967,623\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 4s 478ms/step - loss: 54.1838 - accuracy: 0.0588 - val_loss: 90.5378 - val_accuracy: 0.4286\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 141.9306 - accuracy: 0.4706 - val_loss: 61.0179 - val_accuracy: 0.2857\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 104.5322 - accuracy: 0.2941 - val_loss: 16.0087 - val_accuracy: 0.1429\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 25.8858 - accuracy: 0.1176 - val_loss: 2.7807 - val_accuracy: 0.4286\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 4.7929 - accuracy: 0.2059 - val_loss: 1.4707 - val_accuracy: 0.4286\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 2.3082 - accuracy: 0.4118 - val_loss: 1.5460 - val_accuracy: 0.4286\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 1.3794 - accuracy: 0.5294 - val_loss: 1.4838 - val_accuracy: 0.4286\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 1.3643 - accuracy: 0.5000 - val_loss: 1.5630 - val_accuracy: 0.4286\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 1.2410 - accuracy: 0.5000 - val_loss: 1.6361 - val_accuracy: 0.4286\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 199ms/step - loss: 1.3186 - accuracy: 0.5588 - val_loss: 1.7552 - val_accuracy: 0.2857\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 3s 1s/step - loss: 1.6374 - accuracy: 0.2941 - val_loss: 1.6239 - val_accuracy: 0.4286\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 2s 321ms/step - loss: 1.2963 - accuracy: 0.5588 - val_loss: 1.9305 - val_accuracy: 0.4286\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 199ms/step - loss: 1.4262 - accuracy: 0.5000 - val_loss: 2.0309 - val_accuracy: 0.4286\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 1.4119 - accuracy: 0.5294 - val_loss: 1.7292 - val_accuracy: 0.2857\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 1.4686 - accuracy: 0.4118 - val_loss: 1.6818 - val_accuracy: 0.4286\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 1.3677 - accuracy: 0.5882 - val_loss: 1.7507 - val_accuracy: 0.2857\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 1.2914 - accuracy: 0.5588 - val_loss: 1.7959 - val_accuracy: 0.2857\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 1.2887 - accuracy: 0.5882 - val_loss: 1.7374 - val_accuracy: 0.2857\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 1.2910 - accuracy: 0.4412 - val_loss: 1.7360 - val_accuracy: 0.2857\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 1.2145 - accuracy: 0.4706 - val_loss: 1.7333 - val_accuracy: 0.2857\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 199ms/step - loss: 1.5132 - accuracy: 0.4118 - val_loss: 1.6734 - val_accuracy: 0.4286\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 1.1725 - accuracy: 0.5294 - val_loss: 1.5952 - val_accuracy: 0.4286\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 2s 379ms/step - loss: 0.8432 - accuracy: 0.6176 - val_loss: 1.5455 - val_accuracy: 0.4286\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 2s 406ms/step - loss: 0.7304 - accuracy: 0.7353 - val_loss: 1.5681 - val_accuracy: 0.4286\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.6008 - accuracy: 0.8235 - val_loss: 1.6898 - val_accuracy: 0.4286\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 249ms/step - loss: 0.5874 - accuracy: 0.7647 - val_loss: 1.7114 - val_accuracy: 0.4286\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.6176 - accuracy: 0.7941 - val_loss: 1.6579 - val_accuracy: 0.4286\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.5301 - accuracy: 0.9412 - val_loss: 1.7223 - val_accuracy: 0.4286\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.8027 - accuracy: 0.7059 - val_loss: 1.9127 - val_accuracy: 0.4286\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.6853 - accuracy: 0.8235 - val_loss: 2.2530 - val_accuracy: 0.4286\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.4396 - accuracy: 0.8529 - val_loss: 2.5418 - val_accuracy: 0.4286\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.3151 - accuracy: 0.8529 - val_loss: 2.8223 - val_accuracy: 0.5714\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3280 - accuracy: 0.8824 - val_loss: 2.7000 - val_accuracy: 0.2857\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.3281 - accuracy: 0.8824 - val_loss: 2.6926 - val_accuracy: 0.2857\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 0.1930 - accuracy: 0.9118 - val_loss: 2.8350 - val_accuracy: 0.2857\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 2s 436ms/step - loss: 0.2568 - accuracy: 0.9118 - val_loss: 3.0786 - val_accuracy: 0.2857\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 2s 228ms/step - loss: 0.4336 - accuracy: 0.9118 - val_loss: 3.3995 - val_accuracy: 0.2857\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 0.1722 - accuracy: 0.9412 - val_loss: 3.6381 - val_accuracy: 0.2857\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 204ms/step - loss: 0.1081 - accuracy: 1.0000 - val_loss: 4.2026 - val_accuracy: 0.2857\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.2685 - accuracy: 0.9412 - val_loss: 4.8332 - val_accuracy: 0.4286\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.2724 - accuracy: 0.9118 - val_loss: 5.6854 - val_accuracy: 0.4286\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 6.8831 - val_accuracy: 0.4286\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.2236 - accuracy: 0.9412 - val_loss: 6.2480 - val_accuracy: 0.5714\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 6.4283 - val_accuracy: 0.4286\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.1093 - accuracy: 0.9412 - val_loss: 6.8950 - val_accuracy: 0.2857\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 7.5365 - val_accuracy: 0.2857\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.1788 - accuracy: 0.9706 - val_loss: 5.1585 - val_accuracy: 0.2857\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 2s 367ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.2857\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 2s 402ms/step - loss: 0.0987 - accuracy: 0.9706 - val_loss: 2.5774 - val_accuracy: 0.2857\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 2s 592ms/step - loss: 0.3645 - accuracy: 0.8235 - val_loss: 2.0349 - val_accuracy: 0.4286\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 2s 362ms/step - loss: 0.2870 - accuracy: 0.9118 - val_loss: 1.7154 - val_accuracy: 0.2857\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3330 - accuracy: 0.9706 - val_loss: 1.6439 - val_accuracy: 0.4286\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.5035 - accuracy: 0.9118 - val_loss: 1.8474 - val_accuracy: 0.5714\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 196ms/step - loss: 0.3357 - accuracy: 0.9118 - val_loss: 2.5141 - val_accuracy: 0.2857\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.1502 - accuracy: 0.9706 - val_loss: 3.3604 - val_accuracy: 0.4286\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 193ms/step - loss: 0.2128 - accuracy: 0.9412 - val_loss: 4.2387 - val_accuracy: 0.4286\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.2223 - accuracy: 0.9412 - val_loss: 4.1026 - val_accuracy: 0.4286\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 3.9300 - val_accuracy: 0.4286\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 2s 449ms/step - loss: 0.0427 - accuracy: 0.9706 - val_loss: 4.0022 - val_accuracy: 0.5714\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 2s 415ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 4.1436 - val_accuracy: 0.5714\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 4.3757 - val_accuracy: 0.5714\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 4.5867 - val_accuracy: 0.5714\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 4.8151 - val_accuracy: 0.5714\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 5.0467 - val_accuracy: 0.5714\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 5.1636 - val_accuracy: 0.5714\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 201ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 5.1930 - val_accuracy: 0.5714\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 5.1681 - val_accuracy: 0.5714\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 5.2049 - val_accuracy: 0.5714\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 5.1739 - val_accuracy: 0.5714\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 5.1935 - val_accuracy: 0.5714\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 2s 421ms/step - loss: 0.1089 - accuracy: 0.9706 - val_loss: 6.1114 - val_accuracy: 0.5714\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 2s 418ms/step - loss: 0.0311 - accuracy: 0.9706 - val_loss: 7.1269 - val_accuracy: 0.4286\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 1.2068 - accuracy: 0.8235 - val_loss: 4.9120 - val_accuracy: 0.4286\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.4113 - accuracy: 0.8529 - val_loss: 4.9253 - val_accuracy: 0.2857\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.2187 - accuracy: 0.9412 - val_loss: 4.6903 - val_accuracy: 0.2857\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.0825 - accuracy: 1.0000 - val_loss: 4.8254 - val_accuracy: 0.2857\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.2261 - accuracy: 0.9118 - val_loss: 4.9328 - val_accuracy: 0.4286\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.0728 - accuracy: 0.9706 - val_loss: 5.1508 - val_accuracy: 0.4286\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.0860 - accuracy: 0.9706 - val_loss: 5.4704 - val_accuracy: 0.2857\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.4764 - accuracy: 0.8529 - val_loss: 5.7877 - val_accuracy: 0.2857\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.0625 - accuracy: 0.9706 - val_loss: 7.1263 - val_accuracy: 0.4286\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 202ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 8.9182 - val_accuracy: 0.4286\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 2s 341ms/step - loss: 0.1506 - accuracy: 0.9706 - val_loss: 8.0377 - val_accuracy: 0.4286\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 2s 411ms/step - loss: 0.0553 - accuracy: 0.9706 - val_loss: 7.4404 - val_accuracy: 0.4286\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 203ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 7.5743 - val_accuracy: 0.4286\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 8.0787 - val_accuracy: 0.4286\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.5196 - accuracy: 0.9706 - val_loss: 6.1592 - val_accuracy: 0.4286\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.0664 - accuracy: 0.9706 - val_loss: 3.7803 - val_accuracy: 0.4286\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3218 - accuracy: 0.8235 - val_loss: 3.3561 - val_accuracy: 0.2857\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.5261 - accuracy: 0.8529 - val_loss: 3.7246 - val_accuracy: 0.2857\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.8879 - accuracy: 0.6765 - val_loss: 5.0579 - val_accuracy: 0.4286\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.8758 - accuracy: 0.6176 - val_loss: 5.4921 - val_accuracy: 0.4286\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 239ms/step - loss: 0.7282 - accuracy: 0.7059 - val_loss: 4.2308 - val_accuracy: 0.4286\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 247ms/step - loss: 0.6666 - accuracy: 0.8824 - val_loss: 4.1149 - val_accuracy: 0.5714\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 2s 422ms/step - loss: 0.7651 - accuracy: 0.8824 - val_loss: 4.8415 - val_accuracy: 0.4286\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 2s 383ms/step - loss: 0.5187 - accuracy: 0.8824 - val_loss: 7.0983 - val_accuracy: 0.4286\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 2s 242ms/step - loss: 0.3144 - accuracy: 0.9118 - val_loss: 10.1389 - val_accuracy: 0.4286\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.5933 - accuracy: 0.8529 - val_loss: 6.4217 - val_accuracy: 0.4286\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.1467 - accuracy: 0.9706 - val_loss: 4.7333 - val_accuracy: 0.4286\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 200ms/step - loss: 0.2051 - accuracy: 0.9118 - val_loss: 4.4744 - val_accuracy: 0.4286\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Assuming 'X_train', 'Y_train', 'X_val', and 'Y_val' are your training data and labels, respectively\n",
        "# Replace these with your actual training data and labels\n",
        "\n",
        "# One-hot encode the target labels\n",
        "Y_train_one_hot = to_categorical(Y_train, num_classes=7)\n",
        "Y_val_one_hot = to_categorical(Y_val, num_classes=7)\n",
        "\n",
        "# create model structure\n",
        "emotion_model = Sequential()\n",
        "\n",
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))\n",
        "\n",
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "cv2.ocl.setUseOpenCL(False)\n",
        "# Compile the model\n",
        "emotion_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary for debugging\n",
        "emotion_model.summary()\n",
        "\n",
        "\n",
        "# Create an ImageDataGenerator instance with augmentation settings\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator on your training data\n",
        "datagen.fit(X_train)\n",
        "\n",
        "# Train the model using the augmented data\n",
        "#history = model.fit(datagen.flow(X_train, Y_train, batch_size=32),\n",
        "#epochs=100,\n",
        "                    #validation_data=(X_val, Y_val))\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = emotion_model.fit(X_train, Y_train_one_hot, epochs=100, batch_size=32, validation_data=(X_val, Y_val_one_hot))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "VM8065pa1F2R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CgGwgEQSld5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOW4nzWxrcfS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}